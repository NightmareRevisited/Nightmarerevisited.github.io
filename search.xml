<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>浅谈IO_URING与在GO中的应用</title>
      <link href="/2023/06/26/%E6%B5%85%E8%B0%88IO_URING%E4%B8%8E%E5%9C%A8GO%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"/>
      <url>/2023/06/26/%E6%B5%85%E8%B0%88IO_URING%E4%B8%8E%E5%9C%A8GO%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="浅谈IO-URING与在GO中的应用"><a href="#浅谈IO-URING与在GO中的应用" class="headerlink" title="浅谈IO_URING与在GO中的应用"></a>浅谈IO_URING与在GO中的应用</h1><table><thead><tr><th>Author</th><th>Date</th><th>Version</th></tr></thead><tbody><tr><td>NightmareRevisited</td><td>2023年06月26日</td><td>1.0.0</td></tr></tbody></table><p><a href="http://kernel.dk/io_uring.pdf">io_uring</a> 是 2019 年 <strong>Linux 5.1</strong> 内核首次引入的高性能 <strong>异步 I&#x2F;O 框架</strong>，能显著加速 I&#x2F;O 密集型应用的性能。</p><hr><h2 id="LINUX-IO演变"><a href="#LINUX-IO演变" class="headerlink" title="LINUX IO演变"></a>LINUX IO演变</h2><h3 id="1-基于fd的阻塞式IO"><a href="#1-基于fd的阻塞式IO" class="headerlink" title="1. 基于fd的阻塞式IO"></a>1. 基于fd的阻塞式IO</h3><pre class="language-c" data-language="c"><code class="language-c">ssize_t read(int fd, void *buf, size_t count);ssize_t write(int fd, const void *buf, size_t count);</code></pre><p>linux系统下一切皆文件，kernal提供了基于fd的系统调用read()和write()，这些fd指向的可能是物理文件，也可能是network socket。这两个系统调用称为阻塞式系统调用，用户态调用read和write时会陷入内核进入sleep状态直到数据准备完成，然后将数据从内核态拷贝至用户态。</p><p>阻塞式io sleep时不消耗cpu资源，能及时响应准备就绪的数据。由于每一次系统调用都会阻塞线程，需要为每一个请求分配一个线程，系统开销大，不适用于并发量大的应用。</p><h3 id="2-非阻塞式IO"><a href="#2-非阻塞式IO" class="headerlink" title="2.非阻塞式IO"></a>2.非阻塞式IO</h3><p>随着存储设备越来越快，程序越来越复杂，阻塞式的IO已经不适用了；随后出现了一些非阻塞的系统调用，例如<code>select()</code>,<code>poll()</code>,<code>epoll()</code>，使用这些系统调用读写时不会阻塞（如果监听的所有文件描述符在缓冲区均无数据，系统调用还是会阻塞），而是立刻返回准备就绪文件描述符列表。</p><p>但是这种非阻塞式IO只支持socket和pipe，<code>epoll()</code><strong>甚至连文件存储都不支持</strong>。</p><h3 id="3-通过多线程将IO分离"><a href="#3-通过多线程将IO分离" class="headerlink" title="3. 通过多线程将IO分离"></a>3. 通过多线程将IO分离</h3><p>涉及到物理文件读写的IO，经典的解决方案是通过多线程将IO操作分离，主线程将IO分发给子线程，后者代替主线程进行阻塞式读写，主线程继续执行其他逻辑。但是这种方案的缺陷是线程频繁进行上下文切换，开销非常大。</p><h3 id="4-DIRECT-IO"><a href="#4-DIRECT-IO" class="headerlink" title="4. DIRECT IO"></a>4. DIRECT IO</h3><p>DB软件并不想使用page cache而是直接从设备读写文件，这种方式称为Direct IO。</p><blockquote><ol><li>io操作时需要指定O_DIRECT flag</li><li>需要应用自身管理缓存</li><li>Direct IO是零拷贝</li></ol></blockquote><h3 id="5-异步IO"><a href="#5-异步IO" class="headerlink" title="5. 异步IO"></a>5. 异步IO</h3><blockquote><p>古早时期的aio是posix aio（这也可能是大部分人在课本中学到的），通过signal通知，但是由于本身是glibc在用户态用pthread实现的，性能烂到不如同步调用还有bug，忘了它吧。</p></blockquote><p>随着硬件的发展，存储设备响应速度越来越快，线程间的上下文切换开销占比越来越高。目前一些设备的延迟已经低到和上下文切换一个量级(us)，也就是说，上下文每切换一次，应用就少一次IO机会。</p><p>Kernal 2.6引入了异步IO接口：进程可以通过<code>io_submit()</code>调用IO请求，过一会再调用<code>io_getevent()</code>检查哪些事件准备就绪。2020年左右<strong>aio甚至支持了</strong><code>**epoll()**</code>,同时支持storage IO与network IO，看起来aio似乎成为了异步IO的最终解决方案。<strong>但是</strong>，由于AIO糟糕的迭代，成为最终解决方案也只是一个梦幻泡影，Linus如此评价：</p><blockquote><p>Reply to: <a href="https://lwn.net/Articles/671657/">to support opening files asynchronously</a></p><p><em>So I think this is ridiculously ugly.</em></p><p><em>AIO is a horrible ad-hoc design, with the main excuse being “other, less gifted people, made that design, and we are implementing it for compatibility because database people — who seldom have any shred of taste — actually use it”.</em></p><p>— Linus Torvalds (on lwn.net)</p></blockquote><p>aio存在的问题：</p><ol><li>只支持O_DIRECT flag，对于非db应用几乎是无用的。</li><li>扩展性稀烂。</li><li>理论上aio是非阻塞的，实际上有很多原因会导致阻塞，而且难以预料。</li></ol><h3 id="6-小结"><a href="#6-小结" class="headerlink" title="6. 小结"></a>6. 小结</h3><p>以上可以清晰地看出 Linux IO 的演进：</p><ul><li>最开始是同步（阻塞式）系统调用；</li><li>然后随着<strong>实际需求和具体场景</strong>，不断加入新的异步接口，还要保持与老接口的兼容和协同工作。</li></ul><p>另外也看到，在非阻塞式读写的问题上<strong>并没有形成统一方案</strong>：</p><ol><li>Network IO：添加一个异步接口，然后去轮询请求是否完成；</li><li>Storage IO：<strong>只针对某一细分领域</strong>（数据库）在某一特定时期的需求，添加了一个定制版的异步接口。</li></ol><p><strong>这就是 Linux IO 的演进历史</strong> —— 只着眼当前，出现一个问题就引入一种设计，而并没有多少前瞻性 —— 直到 <code>io_uring</code> 的出现。</p><h2 id="IO-URING"><a href="#IO-URING" class="headerlink" title="IO_URING"></a>IO_URING</h2><p>io_uring 来自facebook资深内核开发者 Jens Axboe 的想法，他在 Linux I&#x2F;O stack 领域颇有研究。 从最早的 patch <a href="https://lwn.net/ml/linux-fsdevel/20181221192236.12866-9-axboe@kernel.dk">aio: support for IO polling</a> 可以看出，这项工作始于一个很简单的观察：随着设备越来越快， <strong>中断驱动（interrupt-driven）模式效率已经低于轮询模式</strong> （polling for completions） —— 这也是高性能领域最常见的主题之一。</p><ul><li><code>io_uring</code> 的<strong>基本逻辑与 linux-aio 是类似的</strong>：提供两个接口，一个将 I&#x2F;O 请求提交到内核，一个从内核接收完成事件。</li><li>但随着开发深入，它逐渐变成了一个完全不同的接口：设计者开始从源头思考 <strong>如何支持完全异步的操作</strong>。</li></ul><h3 id="1-与aio的区别"><a href="#1-与aio的区别" class="headerlink" title="1. 与aio的区别"></a>1. 与aio的区别</h3><ul><li>真正异步：io_uring在系统调用时只是将IO请求放入队列，保证进程永远不会阻塞。</li><li>支持任何类型的IO：storage IO、direct IO、network IO</li><li>灵活可扩展：基于<code>io_uring</code>可以重写linux下的所有系统调用。</li></ul><h3 id="2-底层实现"><a href="#2-底层实现" class="headerlink" title="2. 底层实现"></a>2. 底层实现</h3><p>每个io_uring实例都有两个环形队列，在用户态和内核态之间共享。</p><ul><li>提交队列： SQ</li><li>完成队列： CQ</li></ul><p><img src="/image/io_uring.png" alt="img"></p><p>这两个队列都是单生产者单消费者，size是2的幂，对外暴露无锁接口，内部使用内存壁垒做同步。</p><h3 id="3-使用方式"><a href="#3-使用方式" class="headerlink" title="3. 使用方式"></a>3. 使用方式</h3><h4 id="IO请求"><a href="#IO请求" class="headerlink" title="IO请求"></a>IO请求</h4><ol><li>应用创建SQ entries，更新SQ末端。</li><li>内核消费SQ enties，更新SQ顶端。</li></ol><h4 id="IO就绪"><a href="#IO就绪" class="headerlink" title="IO就绪"></a>IO就绪</h4><ol><li>内核为就绪的一个或多个IO请求创建CQ entries，更新到CQ末端。</li><li>应用消费CQ entries，更新CQ顶端。</li><li>应用消费CQ entries无需切换到内核态。</li></ol><h3 id="4-收益"><a href="#4-收益" class="headerlink" title="4. 收益"></a>4. 收益</h3><p>原来需要多次系统调用的IO请求，使用<code>io_uring</code>可以批处理一次提交。这种批处理能力可以被一些非storage IO使用，例如：<code>read</code>,<code>write</code>,<code>send</code>,<code>recv</code>等。</p><h3 id="5-工作模式"><a href="#5-工作模式" class="headerlink" title="5. 工作模式"></a>5. 工作模式</h3><ul><li>interrupt dirven</li></ul><p><strong>默认模式</strong>。可通过 io_uring_enter() 提交 I&#x2F;O 请求，然后直接检查 CQ 状态判断是否完成。</p><ul><li>polled</li></ul><p>这种模式需要fs和block device支持轮询功能。 相比中断驱动方式，这种方式延迟更低， 但会消耗更多 CPU 资源。</p><p>目前，只有指定了 O_DIRECT flag 打开的文件描述符，才能使用这种模式。当一个read或write请求提交给polled context之后，应用必须调用 <code>io_uring_enter()</code> 来轮询 CQ 队列，判断请求是否已经完成。</p><p>对一个 io_uring 实例来说，<strong>不支持混合使用轮询和非轮询模式</strong>。</p><ul><li>kernal polled</li></ul><p>这种模式中，会 <strong>创建一个内核线程</strong>来执行 SQ 的轮询工作。</p><p>使用这种模式的 io_uring 实例， <strong>应用无需切到到内核态</strong> 就能触发I&#x2F;O 操作。 通过 SQ 来提交 SQE，以及监控 CQ 的完成状态，应用无需任何系统调用，就能提交IO和获取结果。</p><p>如果内核线程的空闲时间超过了用户的配置值，它会通知应用，然后挂起。 这种情况下，应用必须调用 <code>io_uring_enter()</code> 来唤醒内核线程。</p><h3 id="6-系统调用"><a href="#6-系统调用" class="headerlink" title="6. 系统调用"></a>6. 系统调用</h3><h4 id="io-uring-setup"><a href="#io-uring-setup" class="headerlink" title="io_uring_setup"></a>io_uring_setup</h4><pre class="language-c" data-language="c"><code class="language-c">int io_uring_setup(u32 entries, struct io_uring_params *p);</code></pre><p>该系统调用创建一组sq和cq，queue size为下一个大于entries的2的幂，返回文件描述符，用于在该io_uring实例上进行操作。</p><h4 id="io-uring-register"><a href="#io-uring-register" class="headerlink" title="io_uring_register"></a>io_uring_register</h4><pre class="language-c" data-language="c"><code class="language-c">int io_uring_register(unsigned int fd, unsigned int opcode, void *arg, unsigned int nr_args);</code></pre><p>该系统调用注册用于异步IO的文件&#x2F;用户buffer，使得内核能够长时间持有该文件在内核态的数据结构引用，或创建应用内存的长期映射。注册的缓冲区是锁定内存的（提前分配物理内存，节省pagefault开销），并且计入锁定内存限制（<strong>RLIMIT_MEMLOCK</strong>）；每个buffer有1G的限制，且已经注册buffer无法调整大小，想要调整只能先unregister，然后重新register。</p><h4 id="io-uring-enter"><a href="#io-uring-enter" class="headerlink" title="io_uring_enter"></a>io_uring_enter</h4><pre class="language-c" data-language="c"><code class="language-c">int io_uring_enter(unsigned int fd, unsigned int to_submit, unsigned int min_complete, unsigned int flags, sigset_t *sig);</code></pre><p>这个系统调用是io_uring的核心接口，用于提交IO请求、完成IO。每次调用同时执行：1. 提交IO请求 2. 等待IO完成</p><h3 id="7-高级特性"><a href="#7-高级特性" class="headerlink" title="7.高级特性"></a>7.高级特性</h3><h4 id="File-registration"><a href="#File-registration" class="headerlink" title="File registration"></a><strong>File registration</strong></h4><p>针对同一文件进行重复操作的场景，io_uring支持提前注册文件描述符，避免每次指定文件描述符时内核将文件描述符映射到内核态的开销。</p><h4 id="Buffer-registration"><a href="#Buffer-registration" class="headerlink" title="Buffer registration"></a>Buffer registration</h4><p>direct IO场景中，内核需要提前映射内存，io_uring支持提前注册这些缓冲区。</p><h4 id="Poll-ring"><a href="#Poll-ring" class="headerlink" title="Poll ring"></a>Poll ring</h4><p>对于延迟非常低的设备，处理中断的开销是非常大的。io_uring允许用户关闭中断，使用轮询模式。</p><h4 id="Linked-operations"><a href="#Linked-operations" class="headerlink" title="Linked operations"></a>Linked operations</h4><p><a href="http://kernel.dk/io_uring.pdf">io_uring</a>支持用户按一定顺序提交IO请求，IO请求执行顺序严格遵循提交顺序（无并发纯查询ing）。</p><h3 id="8-liburing"><a href="#8-liburing" class="headerlink" title="8. liburing"></a>8. liburing</h3><p>底层的io_uring虽然总共就3个系统调用，但实际使用却非常复杂。liburing提供了一些简单封装的api，使应用避免直接使用底层的系统调用。</p><h2 id="基于liburing的示例"><a href="#基于liburing的示例" class="headerlink" title="基于liburing的示例"></a>基于liburing的示例</h2><p>下面是使用liburing实现的cp命令示例</p><pre class="language-c" data-language="c"><code class="language-c">&#x2F;* SPDX-License-Identifier: MIT *&#x2F;&#x2F;* * gcc -Wall -O2 -D_GNU_SOURCE -o io_uring-cp io_uring-cp.c -luring *&#x2F;#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;assert.h&gt;#include &lt;errno.h&gt;#include &lt;inttypes.h&gt;#include &lt;sys&#x2F;types.h&gt;#include &lt;sys&#x2F;stat.h&gt;#include &lt;sys&#x2F;ioctl.h&gt;#include &lt;liburing.h&gt;#define QD64#define BS(32*1024)static int infd, outfd;struct io_data &#123;    int read;    off_t first_offset, offset;    size_t first_len;    struct iovec iov;&#125;;static int setup_context(unsigned entries, struct io_uring *ring)&#123;    int ret;    ret &#x3D; io_uring_queue_init(entries, ring, 0);    if (ret &lt; 0) &#123;        fprintf(stderr, &quot;queue_init: %s\n&quot;, strerror(-ret));        return -1;    &#125;    return 0;&#125;static int get_file_size(int fd, off_t *size)&#123;    struct stat st;    if (fstat(fd, &amp;st) &lt; 0)        return -1;    if (S_ISREG(st.st_mode)) &#123;        *size &#x3D; st.st_size;        return 0;    &#125; else if (S_ISBLK(st.st_mode)) &#123;        unsigned long long bytes;        if (ioctl(fd, BLKGETSIZE64, &amp;bytes) !&#x3D; 0)            return -1;        *size &#x3D; bytes;        return 0;    &#125;    return -1;&#125;static void queue_prepped(struct io_uring *ring, struct io_data *data)&#123;    struct io_uring_sqe *sqe;    sqe &#x3D; io_uring_get_sqe(ring);    assert(sqe);    if (data-&gt;read)        io_uring_prep_readv(sqe, infd, &amp;data-&gt;iov, 1, data-&gt;offset);    else        io_uring_prep_writev(sqe, outfd, &amp;data-&gt;iov, 1, data-&gt;offset);    io_uring_sqe_set_data(sqe, data);&#125;static int queue_read(struct io_uring *ring, off_t size, off_t offset)&#123;    struct io_uring_sqe *sqe;    struct io_data *data;    data &#x3D; malloc(size + sizeof(*data));    if (!data)        return 1;    sqe &#x3D; io_uring_get_sqe(ring);    if (!sqe) &#123;        free(data);        return 1;    &#125;    data-&gt;read &#x3D; 1;    data-&gt;offset &#x3D; data-&gt;first_offset &#x3D; offset;    data-&gt;iov.iov_base &#x3D; data + 1;    data-&gt;iov.iov_len &#x3D; size;    data-&gt;first_len &#x3D; size;    io_uring_prep_readv(sqe, infd, &amp;data-&gt;iov, 1, offset);    io_uring_sqe_set_data(sqe, data);    return 0;&#125;static void queue_write(struct io_uring *ring, struct io_data *data)&#123;    data-&gt;read &#x3D; 0;    data-&gt;offset &#x3D; data-&gt;first_offset;    data-&gt;iov.iov_base &#x3D; data + 1;    data-&gt;iov.iov_len &#x3D; data-&gt;first_len;    queue_prepped(ring, data);    io_uring_submit(ring);&#125;static int copy_file(struct io_uring *ring, off_t insize)&#123;    unsigned long reads, writes;    struct io_uring_cqe *cqe;    off_t write_left, offset;    int ret;    write_left &#x3D; insize;    writes &#x3D; reads &#x3D; offset &#x3D; 0;    while (insize || write_left) &#123;        unsigned long had_reads;        int got_comp;        &#x2F;*         * Queue up as many reads as we can         *&#x2F;        had_reads &#x3D; reads;        while (insize) &#123;            off_t this_size &#x3D; insize;            if (reads + writes &gt;&#x3D; QD)                break;            if (this_size &gt; BS)                this_size &#x3D; BS;            else if (!this_size)                break;            if (queue_read(ring, this_size, offset))                break;            insize -&#x3D; this_size;            offset +&#x3D; this_size;            reads++;        &#125;        if (had_reads !&#x3D; reads) &#123;            ret &#x3D; io_uring_submit(ring);            if (ret &lt; 0) &#123;                fprintf(stderr, &quot;io_uring_submit: %s\n&quot;, strerror(-ret));                break;            &#125;        &#125;        &#x2F;*         * Queue is full at this point. Find at least one completion.         *&#x2F;        got_comp &#x3D; 0;        while (write_left) &#123;            struct io_data *data;            if (!got_comp) &#123;                ret &#x3D; io_uring_wait_cqe(ring, &amp;cqe);                got_comp &#x3D; 1;            &#125; else &#123;                ret &#x3D; io_uring_peek_cqe(ring, &amp;cqe);                if (ret &#x3D;&#x3D; -EAGAIN) &#123;                    cqe &#x3D; NULL;                    ret &#x3D; 0;                &#125;            &#125;            if (ret &lt; 0) &#123;                fprintf(stderr, &quot;io_uring_peek_cqe: %s\n&quot;,                        strerror(-ret));                return 1;            &#125;            if (!cqe)                break;            data &#x3D; io_uring_cqe_get_data(cqe);            if (cqe-&gt;res &lt; 0) &#123;                if (cqe-&gt;res &#x3D;&#x3D; -EAGAIN) &#123;                    queue_prepped(ring, data);                    io_uring_submit(ring);                    io_uring_cqe_seen(ring, cqe);                    continue;                &#125;                fprintf(stderr, &quot;cqe failed: %s\n&quot;,                        strerror(-cqe-&gt;res));                return 1;            &#125; else if ((size_t)cqe-&gt;res !&#x3D; data-&gt;iov.iov_len) &#123;                &#x2F;* Short read&#x2F;write, adjust and requeue *&#x2F;                data-&gt;iov.iov_base +&#x3D; cqe-&gt;res;                data-&gt;iov.iov_len -&#x3D; cqe-&gt;res;                data-&gt;offset +&#x3D; cqe-&gt;res;                queue_prepped(ring, data);                io_uring_submit(ring);                io_uring_cqe_seen(ring, cqe);                continue;            &#125;            &#x2F;*             * All done. if write, nothing else to do. if read,             * queue up corresponding write.             *&#x2F;            if (data-&gt;read) &#123;                queue_write(ring, data);                write_left -&#x3D; data-&gt;first_len;                reads--;                writes++;            &#125; else &#123;                free(data);                writes--;            &#125;            io_uring_cqe_seen(ring, cqe);        &#125;    &#125;    &#x2F;* wait out pending writes *&#x2F;    while (writes) &#123;        struct io_data *data;        ret &#x3D; io_uring_wait_cqe(ring, &amp;cqe);        if (ret) &#123;            fprintf(stderr, &quot;wait_cqe&#x3D;%d\n&quot;, ret);            return 1;        &#125;        if (cqe-&gt;res &lt; 0) &#123;            fprintf(stderr, &quot;write res&#x3D;%d\n&quot;, cqe-&gt;res);            return 1;        &#125;        data &#x3D; io_uring_cqe_get_data(cqe);        free(data);        writes--;        io_uring_cqe_seen(ring, cqe);    &#125;    return 0;&#125;int main(int argc, char *argv[])&#123;    struct io_uring ring;    off_t insize;    int ret;    if (argc &lt; 3) &#123;        printf(&quot;%s: infile outfile\n&quot;, argv[0]);        return 1;    &#125;      infd &#x3D; open(argv[1], O_RDONLY);    if (infd &lt; 0) &#123;        perror(&quot;open infile&quot;);        return 1;    &#125;    outfd &#x3D; open(argv[2], O_WRONLY | O_CREAT | O_TRUNC, 0644);    if (outfd &lt; 0) &#123;        perror(&quot;open outfile&quot;);        return 1;    &#125;  &#x2F;&#x2F;初始化io_uring sq和cq，如果异常直接退出    if (setup_context(QD, &amp;ring))        return 1;    if (get_file_size(infd, &amp;insize))        return 1;  &#x2F;&#x2F;使用io_uring实现的copy    ret &#x3D; copy_file(&amp;ring, insize);    close(infd);    close(outfd);      &#x2F;&#x2F;关闭io_uring实例    io_uring_queue_exit(&amp;ring);    return ret;&#125;</code></pre><h2 id="benchmark"><a href="#benchmark" class="headerlink" title="benchmark"></a>benchmark</h2><blockquote><p>对于已经在使用aio的应用，不要期待换成io_uring后能获得多少性能提升（即使使用高级特性，也只有5%左右)。<code>io_uring</code> 性能相关的底层机制与 <code>linux-aio</code> 并无本质不同（都是异步提交，轮询结果）。liburing革命性的贡献在于，所有IO场景都能使用异步IO享用其优良特性，而非aio那样仅仅局限于数据库领域的IO。</p></blockquote><blockquote><p>benchmark工具使用rust_echo_bench用于测试不同IO模型下的echo server性能</p><p><a href="https://github.com/haraldh/rust_echo_bench">https://github.com/haraldh/rust_echo_bench</a></p></blockquote><p>这里由于我们自身业务主要为network io，所以在4u机器上对echo server进行benchmark</p><table><thead><tr><th></th><th>c: 100 bytes: 128</th><th>c: 100 bytes: 1024</th><th>c: 500 bytes: 128</th><th>c: 500 bytes: 1024</th><th>c: 1000 bytes: 128</th><th>c: 1000 bytes: 1024</th></tr></thead><tbody><tr><td>net&#x2F;http</td><td>132664</td><td>139206</td><td>133039</td><td>139171</td><td>133480</td><td>139617</td></tr><tr><td>go-uring</td><td>34202</td><td>33159</td><td>147362</td><td>139313</td><td>158483</td><td>154194</td></tr></tbody></table><p>当 batch 比较低时，io_uring 不如 epoll，但当 batch 比较大时，io_uring 场景下系统调用上下文切换开销被极大摊薄，此时 io_uring 的性能是优于 epoll。1000连接时，io_uring 的的吞吐要比 epoll 高 10% 左右。对应到实际应用中，可以通过削减机器增大并发量来压榨出io_uring的性能。</p><h2 id="io-uring与go"><a href="#io-uring与go" class="headerlink" title="io_uring与go"></a>io_uring与go</h2><blockquote><p>目前go中对io_uring的应用还不是很多，下面是github上两个star较多的go iouring项目</p></blockquote><h4 id="github-com-Iceber-iouring-go"><a href="#github-com-Iceber-iouring-go" class="headerlink" title="github.com&#x2F;Iceber&#x2F;iouring-go"></a>github.com&#x2F;Iceber&#x2F;iouring-go</h4><p>该项目主要是用io_uring重写了fs相关的操作，在目前我们项目中的应用场景不大，主要是为storage IO型go编写的轮子</p><h4 id="github-com-godzie44-go-uring"><a href="#github-com-godzie44-go-uring" class="headerlink" title="github.com&#x2F;godzie44&#x2F;go-uring"></a>github.com&#x2F;godzie44&#x2F;go-uring</h4><p>该项目为使用io_uring构建的reactor网络模型，对于io_uring与go netpoll底层使用的epoll的benchmark可以管中窥豹，在reactor模型下io_uring相比标准库net大约能获得10-15%的性能提升。</p>]]></content>
      
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LINK_DIRECTORIES | LINK_LIBRARIES | TARGET_LINK_LIBRARIES区别</title>
      <link href="/2023/05/29/LINK_DIRECTORIES%20%20LINK_LIBRARIES%20%20TARGET_LINK_LIBRARIES%E5%8C%BA%E5%88%AB/"/>
      <url>/2023/05/29/LINK_DIRECTORIES%20%20LINK_LIBRARIES%20%20TARGET_LINK_LIBRARIES%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="LINK-DIRECTORIES-LINK-LIBRARIES-TARGET-LINK-LIBRARIES区别"><a href="#LINK-DIRECTORIES-LINK-LIBRARIES-TARGET-LINK-LIBRARIES区别" class="headerlink" title="LINK_DIRECTORIES | LINK_LIBRARIES | TARGET_LINK_LIBRARIES区别"></a>LINK_DIRECTORIES | LINK_LIBRARIES | TARGET_LINK_LIBRARIES区别</h1><table><thead><tr><th>Author</th><th>Date</th><th>Version</th></tr></thead><tbody><tr><td>NightmareRevisited</td><td>2023年05月29日</td><td>1.0.0</td></tr></tbody></table><hr><blockquote><p>学习io_uring时在cmake编译过程踩了很多坑，专门记录一下</p></blockquote><h2 id="LINK-DIRECTORIES-LINK-LIBRARIES-TARGET-LINK-LIBRARIES区别-1"><a href="#LINK-DIRECTORIES-LINK-LIBRARIES-TARGET-LINK-LIBRARIES区别-1" class="headerlink" title="LINK_DIRECTORIES | LINK_LIBRARIES | TARGET_LINK_LIBRARIES区别"></a>LINK_DIRECTORIES | LINK_LIBRARIES | TARGET_LINK_LIBRARIES区别</h2><h2 id="INCLUDE-DIRECTORIES"><a href="#INCLUDE-DIRECTORIES" class="headerlink" title="INCLUDE_DIRECTORIES"></a>INCLUDE_DIRECTORIES</h2><blockquote><p>添加头文件检索目录</p></blockquote><p>相当于g++选项中的-I参数的作用，也相当于环境变量中增加路径到CPLUS_INCLUDE_PATH变量的作用（这里特指c++。c和<a href="http://lib.csdn.net/base/javaee"><strong>Java</strong></a>中用法类似）。</p><pre class="language-c" data-language="c"><code class="language-c">include_directories(        SYSTEM &quot;&#x2F;usr&#x2F;include&quot;)</code></pre><h2 id="LINK-DIRECTORIES"><a href="#LINK-DIRECTORIES" class="headerlink" title="LINK_DIRECTORIES"></a>LINK_DIRECTORIES</h2><blockquote><p>添加链接库检索路径</p></blockquote><p>语法：</p><p>link_directories(directory1 directory2 …)</p><p>相当于g++命令的-L选项的作用，也相当于环境变量中增加LD_LIBRARY_PATH的路径的作用。</p><pre class="language-c" data-language="c"><code class="language-c">LINK_DIRECTORIES(&quot;&#x2F;usr&#x2F;lib64&quot;)</code></pre><h2 id="LINK-LIBRARIES"><a href="#LINK-LIBRARIES" class="headerlink" title="LINK_LIBRARIES"></a>LINK_LIBRARIES</h2><blockquote><p>添加链接库文件</p></blockquote><pre class="language-c" data-language="c"><code class="language-c">LINK_LIBRARIES(&quot;&#x2F;opt&#x2F;MATLAB&#x2F;R2012a&#x2F;bin&#x2F;glnxa64&#x2F;libeng.so&quot;)LINK_LIBRARIES(eng)LINK_LIBRARIES(&quot;&#x2F;opt&#x2F;MATLAB&#x2F;R2012a&#x2F;bin&#x2F;glnxa64&#x2F;libmx.so&quot;) &#x2F;&#x2F;也可以写在一起LINK_LIBRARIES(    &quot;&#x2F;opt&#x2F;MATLAB&#x2F;R2012a&#x2F;bin&#x2F;glnxa64&#x2F;libeng.so&quot;　    &quot;&#x2F;opt&#x2F;MATLAB&#x2F;R2012a&#x2F;bin&#x2F;glnxa64&#x2F;libmx.so&quot;)</code></pre><h2 id="TARGET-LINK-LIBRARIES"><a href="#TARGET-LINK-LIBRARIES" class="headerlink" title="TARGET_LINK_LIBRARIES"></a><strong>TARGET_LINK_LIBRARIES</strong></h2><blockquote><p>为编译产出指定链接库</p></blockquote><pre class="language-c" data-language="c"><code class="language-c">TARGET_LINK_LIBRARIES(myProject hello)TARGET_LINK_LIBRARIES(myProject libhello.a)TARGET_LINK_LIBRARIES(myProject libhello.so)</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PHP模块迁GO前端页面方案</title>
      <link href="/2023/03/11/PHP%E8%BF%81GO%20HTML%E9%A1%B5%E9%9D%A2%E6%96%B9%E6%A1%88/"/>
      <url>/2023/03/11/PHP%E8%BF%81GO%20HTML%E9%A1%B5%E9%9D%A2%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<h1 id="PHP模块迁GO前端页面方案"><a href="#PHP模块迁GO前端页面方案" class="headerlink" title="PHP模块迁GO前端页面方案"></a>PHP模块迁GO前端页面方案</h1><table><thead><tr><th>Author</th><th>Date</th><th>Version</th></tr></thead><tbody><tr><td>NightmareRevisited</td><td>2023年3月11日</td><td>1.0.0</td></tr></tbody></table><hr><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>业务的同步数据页面（PC端、SEO）使用php的smarty模板框架进行数据注入，但是在go中并没有任何现成模板框架支持php的samrty，所以迁go后如何基于php模块现有模板实现同步页面是一个关键问题。</p><hr><h2 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h2><blockquote><p>在Go语言中，除了标准库自带的html&#x2F;template包之外，还有种类繁多的第三方模板引擎库，这些库大多来自其他语言的经验继承。但是很遗憾，并没有类似smarty模板语法的库。</p></blockquote><table><thead><tr><th>编号</th><th>方案</th><th>学习成本</th><th>rd开发量</th><th>fe开发量</th><th>旧代码复用程度</th><th>维护成本</th><th>上线时间</th></tr></thead><tbody><tr><td>1</td><td>服务端渲染（ssr)</td><td>fe学习成本巨大，除了nodejs ssr渲染外，还需要学习服务器维护管理、持续集成等服务端开发需要的知识，但这显然和fe技术栈没有任何交集</td><td>数据同步页面的后端代码需要改动适配</td><td>巨大</td><td>现有数据同步页面完全无法复用，需要改成支持ssr的页面</td><td>fe需要自己维护ssr集群</td><td>由于fe自身还有业务开发任务，考虑到学习ssr、页面改造、服务器集群搭建及管理维护，很难在短时间PHP完全迁移GO模块</td></tr><tr><td>2</td><td>fe舍弃smarty模板转go模板</td><td>同样，fe学习成本巨大，需要从0学习go的任意一个模板引擎，搭建goserver本地调试也需要从0学习</td><td>无</td><td>巨大</td><td>fe代码完全无法复用</td><td>无</td><td>纯人力堆积方案，同样很难在短时间内做到完全迁移</td></tr><tr><td>3</td><td>smarty模板预编译成go template然后go直接使用</td><td>rd需要学习smarty模板知识，fe新页面开发没有任何改动，仍然使用smarty即可</td><td>中等</td><td>无</td><td>完全可以复用</td><td>无</td><td>即插即用，实现后立刻就可以做到任意功能在go模块开发上线</td></tr></tbody></table><p>考虑到人力成本、学习成本和预期上线问题，最终选择<code>方案3</code>。</p><hr><h2 id="Benchmark"><a href="#Benchmark" class="headerlink" title="Benchmark"></a>Benchmark</h2><blockquote><h4 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h4><ul><li>os: centos7</li><li>cpu: 8</li><li>mem: 16g</li><li>arch: x86_64</li><li>kernal: Linux 6.1.23</li></ul></blockquote><h3 id="php-smarty"><a href="#php-smarty" class="headerlink" title="php smarty"></a>php smarty</h3><pre class="language-json" data-language="json"><code class="language-json">public function testRender()&#123;    $pageData &#x3D; &quot;&quot;;    $pageData &#x3D; json_decode($pageData, true);    $pageData[&quot;isSeo&quot;] &#x3D; 1;    $pageData[&quot;articleList&quot;] &#x3D; [];    $s &#x3D; microtime(true);    $this-&gt;assignTpl($pageData);    for ($i &#x3D; 0; $i &lt; 100; $i++) &#123;        $this-&gt;getView()-&gt;render(&#39;cserviceseo&#x2F;index.tpl&#39;);    &#125;    $e &#x3D; microtime(true);    echo $e-$s;&#125;</code></pre><p>平均一次数据注入花费0.2ms</p><h3 id="go-template"><a href="#go-template" class="headerlink" title="go template"></a>go template</h3><pre class="language-go" data-language="go"><code class="language-go">package mainimport (&quot;encoding&#x2F;json&quot;&quot;fmt&quot;&quot;time&quot;)func main() &#123;var pageDataString string &#x3D; &quot;&quot;var pageData map[string]anyerr :&#x3D; json.Unmarshal([]byte(pageDataString), &amp;pageData)if err !&#x3D; nil &#123;&#x2F;&#x2F;demo&#125;pageData[&quot;isSeo&quot;] &#x3D; 1pageData[&quot;articleList&quot;] &#x3D; []map[string]string&#123;&#125;data :&#x3D; map[string]interface&#123;&#125;&#123;&quot;pageData&quot;:    pageData,&quot;loginStatus&quot;: nil,&#125;s :&#x3D; time.Now().UnixMilli()for i :&#x3D; 0; i &lt; 1000; i++ &#123;_, err :&#x3D; tpl.LoadTpl(&quot;cserviceseo&quot;, data)if err !&#x3D; nil &#123;panic(err)&#125;&#125;e :&#x3D; time.Now().UnixMilli()fmt.Printf(&quot;cost time : %d ms\n&quot;, e-s)&#125;</code></pre><p>平均一次数据注入花费0.6ms</p><h2 id="数据兼容"><a href="#数据兼容" class="headerlink" title="数据兼容"></a>数据兼容</h2><pre class="language-go" data-language="go"><code class="language-go">package mainimport (&quot;bytes&quot;&quot;io&quot;&quot;io&#x2F;fs&quot;&quot;os&quot;&quot;path&#x2F;filepath&quot;&quot;regexp&quot;&quot;strings&quot;)var (smartyTplPath &#x3D; &quot;smarty模板路径&quot;tempTplPath   &#x3D; &quot;中转路径&quot;)func main() &#123;&#x2F;&#x2F;php原始smarty模板转中间模板smarty2Temp()&#x2F;&#x2F;中间模板编译go templatetemp2GoTemplate()&#125;&#x2F;&#x2F; temp2GoTemplate&#x2F;&#x2F; @Description: 中间模板转smartyfunc temp2GoTemplate() &#123;conf :&#x3D; &amp;smarty.Config&#123;LeftDelimiter:  &quot;&lt;%&quot;,RightDelimiter: &quot;%&gt;&quot;,TemplateDir:    tempTplPath,CompileDir:     &quot;webroot&#x2F;aiqifu&#x2F;views&quot;,Ignores:        []string&#123;&quot;inc&#x2F;*&quot;&#125;,UcaseField:     false,CompileOnline:  false,Glob:           false,AutoRoot:       false,Mode:           smartyTypes.Smarty,&#125;fInst, _ :&#x3D; smarty.New(conf)_, err :&#x3D; fInst.CompileAll()if err !&#x3D; nil &#123;panic(err)&#125;&#125;&#x2F;&#x2F; smarty2Temp&#x2F;&#x2F; @Description: 原始smarty模板转中间模板func smarty2Temp() &#123;var tplPathList []stringerr :&#x3D; filepath.Walk(smartyTplPath, func(path string, info fs.FileInfo, err error) error &#123;if info.IsDir() || !tools.StringEndWith(path, &quot;.tpl&quot;) &#123;return nil&#125;path &#x3D; path[len(smartyTplPath)+1:]tplPathList &#x3D; append(tplPathList, path)return nil&#125;)if err !&#x3D; nil &#123;panic(err)&#125;smartyTplBlock :&#x3D; regexp.MustCompile(&quot;&lt;%.*?%&gt;&quot;)variableComp :&#x3D; regexp.MustCompile(&#96;\$[\w.]+&#96;)forLoopStartComp :&#x3D; regexp.MustCompile(&#96;&lt;% *foreach *\$[\w.]+ *as *(\$[\w.]+) *(&#x3D;&gt;)? *(\$[\w.]+)?.*%&gt;&#96;)forLoopEndComp :&#x3D; regexp.MustCompile(&#96;&lt;% *&#x2F; *foreach *%&gt;&#96;)assignmentComp :&#x3D; regexp.MustCompile(&#96;&lt;% *(\$[\w.]+)* *&#x3D;[^&#x3D;].*%&gt;&#96;)for _, tplPath :&#x3D; range tplPathList &#123;smartyTplFile :&#x3D; filepath.Join(smartyTplPath, tplPath)tempTplFile :&#x3D; filepath.Join(tempTplPath, tplPath)smartyFd, err :&#x3D; os.OpenFile(smartyTplFile, os.O_RDONLY, 0666)if err !&#x3D; nil &#123;panic(err)&#125;fileContent :&#x3D; &amp;bytes.Buffer&#123;&#125;_, err &#x3D; io.Copy(fileContent, smartyFd)if err !&#x3D; nil &#123;panic(err)&#125;fileString :&#x3D; fileContent.String()var localVariableStack &#x3D; [][]string&#123;&#123;&quot;$smarty&quot;&#125;, &#x2F;&#x2F;smarty保留变量&#125;smartyBlock :&#x3D; smartyTplBlock.FindAllString(fileString, -1)for _, block :&#x3D; range smartyBlock &#123;&#x2F;&#x2F;判断是否为赋值语句assignmentMatch :&#x3D; assignmentComp.FindStringSubmatch(block)if len(assignmentMatch) &gt; 0 &#123;localVariableStack[len(localVariableStack)-1] &#x3D; append(localVariableStack[len(localVariableStack)-1], assignmentMatch[1])&#125;&#x2F;&#x2F;判断是否为foreachforLoopStartMatch :&#x3D; forLoopStartComp.FindStringSubmatch(block)if len(forLoopStartMatch) &gt; 0 &#123;localVariableStack &#x3D; append(localVariableStack, []string&#123;&#125;)localVariableStack[len(localVariableStack)-1] &#x3D; append(localVariableStack[len(localVariableStack)-1], forLoopStartMatch[1])if forLoopStartMatch[3] !&#x3D; &quot;&quot; &#123;localVariableStack[len(localVariableStack)-1] &#x3D; append(localVariableStack[len(localVariableStack)-1], forLoopStartMatch[3])&#125;&#125;&#x2F;&#x2F;判断是否结束foreachforLoopEndMatch :&#x3D; forLoopEndComp.FindStringSubmatch(block)if len(forLoopEndMatch) &gt; 0 &#123;localVariableStack &#x3D; localVariableStack[:len(localVariableStack)-1]&#125;var newBlock &#x3D; strings.ReplaceAll(block, &quot;&#39;&quot;, &quot;\&quot;&quot;)newBlock &#x3D; strings.ReplaceAll(newBlock, &quot;$smarty.now&quot;, &quot;\&quot;\&quot;|now&quot;)variableList :&#x3D; variableComp.FindAllString(block, -1)for _, variable :&#x3D; range variableList &#123;if isLocalVariable(localVariableStack, variable) &#123;continue&#125;newBlock &#x3D; strings.ReplaceAll(newBlock, variable, variable[:1]+&quot;ROOT.&quot;+variable[1:])&#125;if newBlock !&#x3D; block &#123;fileString &#x3D; strings.ReplaceAll(fileString, block, newBlock)&#125;&#125;&#x2F;&#x2F;摘除所有strip 和 json_encoderule1 :&#x3D; regexp.MustCompile(&#96;&lt;%&#x2F;?strip%&gt;&#96;)rule2 :&#x3D; regexp.MustCompile(&#96;\| *json_encode *&#96;)fileString &#x3D; rule1.ReplaceAllString(fileString, &quot;&quot;)fileString &#x3D; rule2.ReplaceAllString(fileString, &quot;&quot;)tempFd, err :&#x3D; util.CreateFile(tempTplFile)if err !&#x3D; nil &#123;panic(err)&#125;_, err &#x3D; tempFd.WriteString(fileString)if err !&#x3D; nil &#123;panic(err)&#125;&#125;&#125;&#x2F;&#x2F; isLocalVariable&#x2F;&#x2F; @Description: 在作用域中逐层查找变量&#x2F;&#x2F; @param variableStack 作用域（函数栈）&#x2F;&#x2F; @param variable&#x2F;&#x2F; @return boolfunc isLocalVariable(variableStack [][]string, variable string) bool &#123;for _, floor :&#x3D; range variableStack &#123;for _, variablePrefix :&#x3D; range floor &#123;if len(variablePrefix) &gt; len(variable) &#123;continue&#125;if variable[:len(variablePrefix)] &#x3D;&#x3D; variablePrefix &#123;return true&#125;&#125;&#125;return false&#125;</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Rust Programming</title>
      <link href="/2023/01/27/rust/"/>
      <url>/2023/01/27/rust/</url>
      
        <content type="html"><![CDATA[<h1 id="Rust-Programing-Language"><a href="#Rust-Programing-Language" class="headerlink" title="Rust Programing Language"></a>Rust Programing Language</h1><table><thead><tr><th>Author</th><th>Date</th><th>Version</th></tr></thead><tbody><tr><td><a href="yangchangning@baidu.com">杨倡宁</a></td><td>2023年1月27日</td><td>1.0.0</td></tr></tbody></table><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在2009年的一个会议中，著名的“快速排序”算法的发明者，Tony Hoare向全世界道歉，忏悔他曾经发明了“空指针”这个玩意。他是这么说的：</p><pre class="language-plain" data-language="plain"><code class="language-plain">我把它叫做我的“十亿美元错误”，就是在1965年发明了空引用… 我无法抵挡放进一个空引用的诱惑，仅仅是因为实现起来非常容易。</code></pre><p>这几十年来程序员在和因Null造成的空指针异常的斗争中，犯的错误以及解决错误所耗费的时间精力，应该远远不止十亿美元。</p><h2 id="什么是RUST"><a href="#什么是RUST" class="headerlink" title="什么是RUST"></a>什么是RUST</h2><p>Rust 是由 Mozilla 开发的<a href="https://www.zhihu.com/search?q=%E5%A4%9A%E8%8C%83%E5%BC%8F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2119131573%7D">多范式编程语言</a>，专注于性能和安全性。Rust 以其先进的<strong>安全并发能力</strong>而闻名 。Rust 的语法类似于 C++，但它提供了更快的速度和内存安全性，没有空指针，没有gc。</p><blockquote><p>Rust 最初是为 Mozilla Firefox 浏览器开发的，但它的效率和优势吸引了许多 C++ 开发人员开始使用 Rust，常见于区块链、OS开发。</p></blockquote><h2 id="为什么使用Rust"><a href="#为什么使用Rust" class="headerlink" title="为什么使用Rust"></a>为什么使用Rust</h2><p>编程很难。</p><p>不是因为我们人体本身构造复杂，而是因为我们都只是人类。我们的注意力持续时间有限，记忆也不是永久的——换句话说，我们往往会犯错。电脑和软件无处不在：在太空中，天上，地面，佩戴在身上，甚至在我们的身体里。每天都有越来越多的系统实现自动化，越来越多的生命依赖于软件及其质量，航空电子设备，自动驾驶汽车，核电站，交通控制系统，植入式心脏起搏器。这些系统中的bug几乎总是危及人类的生命。</p><p>“程序正确性是通过测试来检验的”和“程序正确性是经过逻辑验证的”之间存在着巨大的差异。不幸的是，即使我们对代码的每一行都进行了测试，我们仍然不能确保它是正确的。然而，拥有一个形式系统来证明我们的代码是正确的(至少在某些方面是正确的)则是另一回事了。</p><p>「Rust作为一种编程语言」的不同之处，不是因为它的花哨语法或受欢迎的社区，而是因为人们在使用它编写程序时能获得信心。Rust非常严格并且追究细节的编译器会检查你使用的每个变量和引用的每个内存地址。它可能看起来会妨碍你编写高效且富有表现力的代码，但令人惊讶的是，恰恰相反：编写一个有效且稳定的Rust程序实际上比编写一个有潜在危险的程序更容易。在后一种情况下，你将与编译器发生冲突，因为你尝试的几乎所有操作都会导致内存安全问题。</p><p>为什么学习使用Rust？因为它让我们可以毫无畏惧地编写复杂而且高性能的软件。我们可以自由地进行实验，因为我们确信Rust将为我们提供支撑。无论是实现一个简单的命令行实用程序还是一个多线程庞然大物，它都没有什么区别。Rust确保我们的程序不存在未定义的行为、数据竞争或任何内存安全问题。</p><p>内存bug之所以难以发现，是因为你不能轻松地编写测试来捕获它。如果你在beta测试期间没有发现bug，那么它可能会在代码中存在数年，就像定时炸弹等待着爆炸的那一刻。当然，也有像Valgrind这样的工具可以帮助捕获这些bug。但即使是Valgrind，如果问题发生时不是执行在调试模式下，或者执行时没有表现为内存方面的问题，它也不会捕获到bug。</p><p>因此，通过使用Rust，我们消除了最复杂、最不可预测的一类错误。</p><h3 id="媲美C-C-的高性能"><a href="#媲美C-C-的高性能" class="headerlink" title="媲美C&#x2F;C++的高性能"></a>媲美C&#x2F;C++的高性能</h3><p>数据来源：<a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame">benchmarksgame</a></p><h4 id="RUST-VS-C"><a href="#RUST-VS-C" class="headerlink" title="RUST VS C"></a>RUST VS C</h4><ul><li>fannkuch-redux</li></ul><table><thead><tr><th>source</th><th>mem</th><th>gz</th><th>cpu</th></tr></thead><tbody><tr><td>C</td><td>11236</td><td>1576</td><td>8.34</td></tr><tr><td>Rust</td><td>11036</td><td>1253</td><td>13.93</td></tr></tbody></table><ul><li>n-body</li></ul><table><thead><tr><th>source</th><th>mem</th><th>gz</th><th>cpu</th></tr></thead><tbody><tr><td>C</td><td>11392</td><td>1633</td><td>2.08</td></tr><tr><td>Rust</td><td>11068</td><td>1874</td><td>2.81</td></tr></tbody></table><h4 id="RUST-VS-C-1"><a href="#RUST-VS-C-1" class="headerlink" title="RUST VS C++"></a>RUST VS C++</h4><ul><li>fannkuch-redux</li></ul><table><thead><tr><th>source</th><th>mem</th><th>gz</th><th>cpu</th></tr></thead><tbody><tr><td>C++</td><td>10936</td><td>1528</td><td>12.80</td></tr><tr><td>Rust</td><td>11036</td><td>1253</td><td>13.93</td></tr></tbody></table><ul><li>n-body</li></ul><table><thead><tr><th>source</th><th>mem</th><th>gz</th><th>cpu</th></tr></thead><tbody><tr><td>C++</td><td>10960</td><td>1927</td><td>2.14</td></tr><tr><td>Rust</td><td>11068</td><td>1874</td><td>2.81</td></tr></tbody></table><ul><li>spectral-norm</li></ul><table><thead><tr><th>source</th><th>mem</th><th>gz</th><th>cpu</th></tr></thead><tbody><tr><td>C++</td><td>10984</td><td>1044</td><td>2.84</td></tr><tr><td>Rust</td><td>11124</td><td>1126</td><td>2.84</td></tr></tbody></table><h4 id="RUST-VS-GO"><a href="#RUST-VS-GO" class="headerlink" title="RUST VS GO"></a>RUST VS GO</h4><ul><li>fannkuch-redux</li></ul><table><thead><tr><th>source</th><th>mem</th><th>gz</th><th>cpu</th></tr></thead><tbody><tr><td>Go</td><td>10884</td><td>969</td><td>32.39</td></tr><tr><td>Rust</td><td>11036</td><td>1253</td><td>13.93</td></tr></tbody></table><ul><li>n-body</li></ul><table><thead><tr><th>source</th><th>mem</th><th>gz</th><th>cpu</th></tr></thead><tbody><tr><td>Go</td><td>10968</td><td>1200</td><td>6.37</td></tr><tr><td>Rust</td><td>11068</td><td>1874</td><td>2.81</td></tr></tbody></table><ul><li>spectral-norm</li></ul><table><thead><tr><th>source</th><th>mem</th><th>gz</th><th>cpu</th></tr></thead><tbody><tr><td>Go</td><td>10972</td><td>411</td><td>5.32</td></tr><tr><td>Rust</td><td>11124</td><td>1126</td><td>2.84</td></tr></tbody></table><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li>Rust 消除数据竞争，天生线程安全，解放多线程生产力，是 Rust 明显比 C &#x2F; C++ &#x2F; Go 等语言优越的地方。</li><li>Rust 语言支持异步高并发编程。</li><li>Rust 支持 安全的编译期计算，在编译器提前暴露问题的排查修复成本远远低于rumtime error。</li><li>Rust许多特性实现了零代价抽象：你不会为没使用的功能付出代价，而对使用了的功能，你无法手写出更好的代码。</li><li>Rust是一门完美契合软件工程思想的语言：通过逻辑证明正确性而不是测试；尽可能早的暴露问题以降低维护返工成本；通过safe与unsafe两种模式区分开发内容：高级开发人员负责开发unsafe部分；基础开发人员负责开发safe的业务逻辑部分（只要能过编译就绝对没有内存等严重非逻辑问题），在项目管理中同时具备分工协作的高效性与程序的稳定可靠性。</li></ol><h3 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h3><ol><li>Rust 编译速度很慢。虽然 Rust 官方也一直在改进 Rust 编译速度，包括增量编译支持，引入新的编译后端（ cranelift ），并行编译等措施，但还是慢。而且 增量编译目前也有 Bug。</li><li>学习曲线陡峭。</li><li>缺乏针对 Rust 中使用unsafe部分的检测工具。</li><li>针对某些场景、架构和硬件生态支持不是很完善，这其实是需要投入人力和硬件成本来支持了，需要社区和生态的共同努力。</li></ol><h2 id="FEATURE简介"><a href="#FEATURE简介" class="headerlink" title="FEATURE简介"></a>FEATURE简介</h2><h3 id="内存与分配"><a href="#内存与分配" class="headerlink" title="内存与分配"></a>内存与分配</h3><p>在有 <strong>垃圾回收</strong>（<em>garbage collector</em>，<em>GC</em>）的语言中， GC 记录并清除不再使用的内存，而我们并不需要关心它。没有 GC 的话，识别出不再使用的内存并调用代码显式释放就是我们的责任了，跟请求内存的时候一样。从历史的角度上说正确处理内存回收曾经是一个困难的编程问题。如果忘记回收了会浪费内存。如果过早回收了，将会出现无效变量。如果重复回收，这也是个 bug。我们需要精确地为一个 <code>allocate</code> 配对一个 <code>free</code></p><p>Rust 采取了一个不同的策略：内存在拥有它的变量离开作用域后就被自动释放。例如：</p><pre class="language-rust" data-language="rust"><code class="language-rust">fn foo() &#123;&#123;        let s &#x3D; String::from(&quot;hello&quot;); &#x2F;&#x2F; 从此处起，s 开始有效        &#x2F;&#x2F; 使用 s    &#125;        &#x2F;&#x2F;此时s已被释放，不可用&#125;</code></pre><p>这是一个将 <code>String</code> 需要的内存返回给分配器的很自然的位置：当 <code>s</code> 离开作用域的时候。当变量离开作用域，Rust 为我们调用一个特殊的函数。这个函数叫做 ，在这里 <code>String</code> 的作者可以放置释放内存的代码。Rust 在结尾的 <code>&#125;</code> 处自动调用 <code>drop</code>。</p><h3 id="所有权"><a href="#所有权" class="headerlink" title="所有权"></a>所有权</h3><p>下面这段代码将会无法通过编译</p><pre class="language-rust" data-language="rust"><code class="language-rust">fn foo() &#123;    let s1 &#x3D; String::from(&quot;hello&quot;);    let s2 &#x3D; s1;    println!(&quot;&#123;&#125;, world!&quot;, s1);&#125;</code></pre><p>原因是<code>string hello</code>的所有权已从s1转移到s2上，s1已无法使用。</p><p>在内存与分配中了解到当变量离开作用域后，Rust 自动调用 <code>drop</code> 函数并清理变量的堆内存。如果<code>s2</code>和<code>s1</code>同时具备所有权，那么当 <code>s2</code> 和 <code>s1</code> 离开作用域，他们都会尝试释放相同的内存。这是一个叫做 <strong>二次释放</strong>（<em>double free</em>）的错误，也是之前提到过的内存安全性 bug 之一。两次释放（相同）内存会导致内存污染，它可能会导致潜在的安全漏洞。</p><blockquote><p>存储在栈上的数据（所有基础类型）由于拷贝速度很快，所以在赋值后两个变量会同时具备所有权。</p></blockquote><p>变量的所有权总是遵循相同的模式：将值赋给另一个变量时移动它。当持有堆中数据值的变量离开作用域时，其值将通过 <code>drop</code> 被清理掉，除非数据被移动为另一个变量所有。</p><h4 id="借用与引用"><a href="#借用与引用" class="headerlink" title="借用与引用"></a>借用与引用</h4><pre class="language-rust" data-language="rust"><code class="language-rust">fn main() &#123;    let s1 &#x3D; String::from(&quot;hello&quot;);    let (len,s1) &#x3D; calculate_length(s1);    println!(&quot;The length of &#39;&#123;&#125;&#39; is &#123;&#125;.&quot;, s1, len);&#125;fn calculate_length(s: String) -&gt; (usize, String) &#123;    (s.len(),s)&#125;</code></pre><p>在每一个函数中都获取所有权并接着返回所有权有些啰嗦，这个时候借用能够有效的简化代码。</p><pre class="language-rust" data-language="rust"><code class="language-rust">fn main() &#123;    let s1 &#x3D; String::from(&quot;hello&quot;);    let len &#x3D; calculate_length(&amp;s1);    println!(&quot;The length of &#39;&#123;&#125;&#39; is &#123;&#125;.&quot;, s1, len);&#125;fn calculate_length(s: &amp;String) -&gt; usize &#123;    s.len()&#125;</code></pre><p>这些 &amp; 符号就是 <strong>引用</strong>，它们允许你使用值但不获取其所有权。</p><p>引用又区分为可变引用与不可变引用，可变引用允许在其他作用域中修改变量内部的值。</p><p>不过可变引用有一个很大的限制：在同一时间，只能有一个对某一特定数据的可变引用。防止同一时间对同一数据进行多个可变引用的限制允许可变性，不过是以一种受限制的方式允许。这个限制的好处是 Rust 可以在编译时就避免数据竞争。类似的规则也存在于同时使用可变与不可变引用中：持有一个可变引用时无法持有不可变引用，使用者可不希望不可变引用的值在他们的眼皮底下突然被改变了；然而，多个不可变引用是可以的，因为没有哪个只能读取数据的人有能力影响其他人读取到的数据。</p><blockquote><p>一些代码“拥有”一个指向内存的特定指针。 它是该指针的唯一所有者。 它还可以暂时将该内存借给其他代码：代码“借用”它。 借用它一段时间，称为“生命周期”。</p></blockquote><h3 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a>生命周期</h3><p>先看一段C++的悬垂指针代码</p><pre class="language-cpp" data-language="cpp"><code class="language-cpp">int *foo_int(void)&#123;    int i &#x3D; 1234;    &amp;i&#125;int add_one(void)&#123;    int *num &#x3D; foo_int();    *num + 1&#125;</code></pre><p>foo_int函数在栈上分配了一个整型，然后保存给一个变量i，最后返回了这个变量i的引用。这里有一个问题：当函数返回时栈内存变成失效。意味着在函数add_one第二行，指针num指向了垃圾值，我们将无法得到想要的结果。虽然这个一个简单的例子，但是在C++的代码里会经常发生。当堆上的内存使用malloc（或new）分配，然后使用free（或delete）释放时，会出现类似的问题，但是您的代码会尝试使用指向该内存的指针执行某些操作。 更现代的C ++使用RAII和构造函数&#x2F;析构函数，但它们无法完全避免“悬垂指针”。 这个问题被称为“悬垂指针”，在rust中悬垂指针将无法通过编译。</p><pre class="language-rust" data-language="rust"><code class="language-rust">fn foo_u32() -&gt; &amp;u32&#123;    let i &#x3D; 1;    &amp;i&#125;</code></pre><p>编译报错</p><pre class="language-rust" data-language="rust"><code class="language-rust">error[E0106]: missing lifetime specifier  --&gt; src&#x2F;main.rs:60:17   |60 | fn foo_u32() -&gt; &amp;u32&#123;   |                 ^ expected named lifetime parameter   |   &#x3D; help: this function&#39;s return type contains a borrowed value, but there is no value for it to be borrowed fromhelp: consider using the &#96;&#39;static&#96; lifetime   |60 | fn foo_u32() -&gt; &amp;&#39;static u32&#123;   |                  +++++++</code></pre><p>实际上在新版本即使加上静态生命周期（指该内存在整个程序运行期间都不会释放，该应用在程序运行期间总是有效的）描述仍然会引发编译报错。</p><pre class="language-rust" data-language="rust"><code class="language-rust">fn foo_u32() -&gt; &amp;&#39;static u32&#123;    let i &#x3D; 1;    &amp;i&#125;error[E0515]: cannot return reference to local variable &#96;i&#96;  --&gt; src&#x2F;main.rs:62:5   |62 |     &amp;i   |     ^^ returns a reference to data owned by the current function</code></pre><p>新版本中禁止将作用域创建的变量引用传递至父作用域，彻底杜绝悬垂指针，当然这里和生命周期关系不大，就不细说了。</p><p>Rust 编译器有一个 借用检查器（<em>borrow checker</em>），它比较作用域来确保所有的借用都是有效的。</p><pre class="language-rust" data-language="rust"><code class="language-rust">&#123;    let r;                &#x2F;&#x2F; ---------+-- &#39;a                          &#x2F;&#x2F;          |    &#123;                     &#x2F;&#x2F;          |        let x &#x3D; 5;        &#x2F;&#x2F; -+-- &#39;b  |        r &#x3D; &x;           &#x2F;&#x2F;  |       |    &#125;                     &#x2F;&#x2F; -+       |                          &#x2F;&#x2F;          |    println!(&quot;r: &#123;&#125;&quot;, r); &#x2F;&#x2F;          |&#125;                         &#x2F;&#x2F; ---------+</code></pre><p>这里将 <code>r</code> 的生命周期标记为 <code>&#39;a</code> 并将 <code>x</code> 的生命周期标记为 <code>&#39;b</code>。如你所见，内部的 <code>&#39;b</code> 块要比外部的生命周期 <code>&#39;a</code> 小得多。在编译时，Rust 比较这两个生命周期的大小，并发现 <code>r</code> 拥有生命周期 <code>&#39;a</code>，不过它引用了一个拥有生命周期 <code>&#39;b</code> 的对象。程序被拒绝编译，因为生命周期 <code>&#39;b</code> 比生命周期 <code>&#39;a</code> 要小：被引用的对象比它的引用者存在的时间更短。</p><p>上述是编译器能够检查出引用者和被引用对象的生命周期时的情况，当编译器无法比较生命周期时，会硬性要求手动添加生命周期描述符。</p><p>例如：</p><pre class="language-rust" data-language="rust"><code class="language-rust">fn longest(x: &amp;str, y: &amp;str) -&gt; &amp;str &#123;    if x.len() &gt; y.len() &#123;        x    &#125; else &#123;        y    &#125;&#125;</code></pre><p>当我们定义这个函数的时候，并不知道传递给函数的具体值，所以也不知道到底是 <code>if</code> 还是 <code>else</code> 会被执行。我们也不知道传入的引用的具体生命周期，所以也就不能通过观察作用域来确定返回的引用是否总是有效。借用检查器自身同样也无法确定，因为它不知道 <code>x</code> 和 <code>y</code> 的生命周期是如何与返回值的生命周期相关联的。</p><pre class="language-rust" data-language="rust"><code class="language-rust">fn longest&lt;&#39;a&gt;(x: &amp;&#39;a str, y: &amp;&#39;a str) -&gt; &amp;&#39;a str &#123;    if x.len() &gt; y.len() &#123;        x    &#125; else &#123;        y    &#125;&#125;</code></pre><p>在添加泛型生命周期标注后，编译器可以知道longest函数中，参数x,y还有返回值的生命周期都是相同的’a，它的实际含义是 <code>longest</code> 函数返回的引用的生命周期与传入该函数的引用的生命周期的较小者一致，当具体的引用被传递给 <code>longest</code> 时，被 <code>&#39;a</code> 所替代的具体生命周期是 <code>x</code> 的作用域与 <code>y</code> 的作用域相重叠的那一部分。因为我们用相同的生命周期参数 <code>&#39;a</code> 标注了返回的引用值，所以返回的引用值就能保证在 <code>x</code> 和 <code>y</code> 中较短的那个生命周期结束之前保持有效。</p><h3 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h3><p>rust的并发编程与go有很多相似之处。</p><h4 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h4><p>在rust中启用多线程就像go语言启用协程一样简单。</p><pre class="language-rust" data-language="rust"><code class="language-rust">use std::time::Duration;fn test_thread() &#123;    for i in 1..10 &#123;        println!(&quot;hi number &#123;&#125; from the spawned thread!&quot;, i);        std::thread::sleep(Duration::from_millis(1));    &#125;&#125;fn main() &#123;    std::thread::spawn(test_thread);    for i in 1..5 &#123;        println!(&quot;hi number &#123;&#125; from the main thread!&quot;, i);        std::thread::sleep(Duration::from_millis(1));    &#125;&#125;</code></pre><p>使用标准库中的thread::spawn即可，与go存在些许差别。</p><ol><li>go是关键字，spawn是函数调用</li><li>go可以传参，spawn无法传参，需要通过闭包将参数透传。</li><li>go协程无法干预运行行为以及获取运行状态，spawn会返回一个线程的handler，可以用于获取线程状态以及控制线程行为（类似于python multithread库）</li><li>go使用的是轻量级协程，spawn使用标准线程。</li></ol><h4 id="通道channel"><a href="#通道channel" class="headerlink" title="通道channel"></a>通道channel</h4><blockquote><p>不要通过共享内存来通讯；而是通过通讯来共享内存</p></blockquote><p>通道有两部分组成，一个发送者（transmitter）和一个接收者（receiver）。发送者位于上游位置，在这里可以将橡皮鸭放入河中，接收者则位于下游，橡皮鸭最终会漂流至此。代码中的一部分调用发送者的方法以及希望发送的数据，另一部分则检查接收端收到的消息。当发送者或接收者任一被丢弃时可以认为通道被 <strong>关闭</strong>（<em>closed</em>）了。</p><p>示例：</p><pre class="language-rust" data-language="rust"><code class="language-rust">fn main() &#123;    let (tx,rx) &#x3D; channel();    &#x2F;&#x2F;tx是发送者，rx是接受者    tx.send(1).unwrap();    tx.send(2).unwrap();    drop(tx);        let i &#x3D; rx.recv().unwrap();    println!(&quot;&#123;&#125;&quot;,i);    let i &#x3D; rx.recv().unwrap();    println!(&quot;&#123;&#125;&quot;,i);&#125;</code></pre><p>rust的channel和go存在部分差异</p><ol><li>channel创建出的是无限缓冲区的通道，如果需要有限缓冲区，则需要使用sync_channel，使用有限缓冲区大小的通道时，发送&#x2F;接收的阻塞逻辑与go相同。</li><li>rust创建channel时无需声明类型，编译器会根据后续首次对通道进行的发送&#x2F;接收操作为通道确定类型。</li></ol><p>所有权同样存在于通道中：</p><ol><li>一个通道可以clone出多个发送者，但一个通道只能有一个接受者。</li><li>通道中发送变量会夺走其所有权。</li></ol><h2 id="业内应用"><a href="#业内应用" class="headerlink" title="业内应用"></a>业内应用</h2><ol><li>在安卓 13 中，共有 150 万行 Rust 代码，约占所有新代码的 21%。</li><li>知乎elasticsearch检索引擎，搜索技术团队基于 Lucene、使用 Rust 语言重写的一套搜索引擎核心库Rucene。</li><li>👍厂内自研bpfs，除了成熟 c&#x2F;c++ 组件（比如 rocksDB）外，99%由rust实现，全闪存储中小文件性能世界第一。</li><li>字节跳动飞书客户端。</li><li>Rust For Linux。</li></ol><h2 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h2><ol><li><a href="https://rustwiki.org/zh-CN/book/title-page.html">Rust程序设计语言（wiki）</a></li><li>《Rust程序设计》（螃蟹书）</li></ol><p>螃蟹书知识体系讲解不是线性的，前置章节中经常会带入靠后的知识，导致完全没有基础的情况下非常晦涩难懂，但针对feature的讲解比较深入；而wiki讲解浅显易懂且循序渐进。建议在读完wiki后再看螃蟹书。</p><blockquote><p>【最短的捷径就是绕远路】</p><p>学习Rust有没有捷径，有：Rust在很多feature上都与haskell有相似之处，例如枚举、trait、函数式编程，有haskell基础学习rust会更简单。但是不推荐无haskell和rust经验的人先学习haskell，因为haskell要比rust更困难。</p></blockquote><h3 id="开发工具"><a href="#开发工具" class="headerlink" title="开发工具"></a>开发工具</h3><ol><li>Clion + Rust插件</li><li>目前Jetbrains适配了单独的RustRover，但为beta版本，可能存在bug。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Rust </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MONGODB 分片选择</title>
      <link href="/2021/12/27/%E5%88%86%E7%89%87/"/>
      <url>/2021/12/27/%E5%88%86%E7%89%87/</url>
      
        <content type="html"><![CDATA[<h1 id="MONGODB-分片选择"><a href="#MONGODB-分片选择" class="headerlink" title="MONGODB 分片选择"></a>MONGODB 分片选择</h1><table><thead><tr><th>Author</th><th>Version</th><th>Date</th></tr></thead><tbody><tr><td>NightmareRevisited</td><td>1.0.0</td><td>2021年12月27日</td></tr></tbody></table><hr><h2 id="名词概述"><a href="#名词概述" class="headerlink" title="名词概述"></a>名词概述</h2><h3 id="Replica-Set"><a href="#Replica-Set" class="headerlink" title="Replica Set"></a>Replica Set</h3><blockquote><p>中文：副本集</p></blockquote><p>MongoDB中的副本集是一组维护相同数据集合的 <a href="https://docs.mongodb.com/manual/reference/program/mongod/#bin.mongod">mongod</a>进程。副本集提供了冗余和<a href="https://docs.mongodb.com/manual/reference/glossary/#term-high-availability">高可用性</a>，并且这是所有生产部署的基础。通常一组Replica Set由一个Primary(master)和若干个Secondary(slave)还有Arbiter构成。</p><p>在Replica Set中，Primary是唯一能够接收写请求的节点。MongoDB在 Primary上进行写操作，并会将这些操作记录到Primary的 oplog中。 Secondary会将oplog复制到其本机并将这些操作应用到其自己的数据集上。</p><p>Secondary的数据集与Primary中的一致，默认配置下Secondary不处理任何请求，但是可以通过配置SlaveOk，使得读请求可以在Secondary上进行。</p><p>Arbiter通常在Replica Set中只有偶数节点时加入，不存储节点数据，只参与投票选举，选举算法Bully此处不再赘述，八股文自行背诵。</p><h3 id="Sharding"><a href="#Sharding" class="headerlink" title="Sharding"></a>Sharding</h3><p>Sharding是一种将数据分配到多个机器上的方法。MongoDB通过分片技术来支持具有海量数据集和高吞吐量操作的部署方案。</p><p>数据库系统的数据集或应用的吞吐量比较大的情况下，会给单台服务器的处理能力带来极大的挑战。例如，高查询率会耗尽服务器的CPU资源。工作的数据集大于系统的内存压力、磁盘驱动器的I&#x2F;O容量。</p><p>常见的解决系统增长的方式有两种：垂直扩展，水平扩展。</p><p>垂直扩展在Quantum民用前成本过高而且存在上限基本不用考虑。</p><p>水平扩展是通过将系统数据集划分至多台机器，并根据需要添加服务器来提升容量。虽然单个机器的总体速度或容量可能不高，但每台机器只需处理整个数据集的某个子集，所以可能会提供比单个高速大容量服务器更高的效率，而且机器的数量只需要根据数据集大小来进行扩展，与单个机器的高端硬件相比，这个方案可以降低总体成本。不过，这种方式会提高基础设施部署维护的复杂性。</p><p>MongoDB通过Sharding实现水平扩展，实现类似于Redis的Twemproxy。</p><h3 id="Chunk"><a href="#Chunk" class="headerlink" title="Chunk"></a>Chunk</h3><p>MongoDB将分片数据拆分成<a href="https://docs.mongodb.com/manual/reference/glossary/#term-chunk">块</a>。每个Chunk上根据分片类型选择和ShardKey存储数据，默认Chunk大小为64MB，可以在config replica中为指定库自定义块大小。当一个Chunk中数据大小超过64MB且可以分割时，将会在后台由Balancer将该Chunk分裂为两个更小粒度的Chunk并均衡不同shard上。</p><h2 id="balancer机制"><a href="#balancer机制" class="headerlink" title="balancer机制"></a>balancer机制</h2><blockquote><p>mongodb 在shard上均衡数据的单位是chunk而不是doc，会尽量平衡每个shard上chunk的数量，如果shardkey选择不合理&#x2F;doc大小方差较大，会引起io不均衡。</p></blockquote><ol><li>　　balancer向源shard发送moveChunk命令</li><li>　　源shard内部执行moveChunk命令，并保证在迁移的过程中，新插入的document还是写入源shard</li><li>　　如果需要的话，目标shard创建需要的索引</li><li>　　目标shard从源shard请求数据；<strong>注意，这里是一个copy操作，而不是move操作</strong></li><li>　　在接收完chunk的最后一个文档后，目标shard启动一个同步拷贝进程，保证拷贝到在迁移过程中又写入源shard上的相关文档</li><li>　　完全同步之后，目标shard向config server报告新的metadata（chunk的新位置信息）</li><li>　　在上一步完成之后，源shard开始删除旧的document</li></ol><p>为了加速迁移速度，Step 7不会立即执行，而是进入一个异步队列在合适的时机执行，在delete phase完全执行完前，源chunk中会存在冗余的orphaned document，此时部分查询语句的结果将暂时异常返回，例如对shardkey的$in查询，不合理的count查询(db.col.count)</p><h2 id="SHARD-RULE"><a href="#SHARD-RULE" class="headerlink" title="SHARD RULE"></a>SHARD RULE</h2><blockquote><p>mongoDB有两种分片规则：哈希分片和范围分片</p></blockquote><h3 id="Ranged-Sharding"><a href="#Ranged-Sharding" class="headerlink" title="Ranged Sharding"></a>Ranged Sharding</h3><p>范围分片是mongodb默认的分片规则，基于范围的分片会将数据划分为由片键值确定的连续范围。 在此模型中，具有“接近”片键值的文档可能位于相同的Chunk或者Shard中。</p><p>官方建议范围分片适用于shardkey均匀分布在若干个区间内的数据，对于递增&#x2F;递减型的数据范围分片效果不是很理想，所有的split都发生在new data中；如果业务模型对于new data存在高频的读写，自动触发的split对性能压力无疑是雪上加霜。如果业务的数据模型是递增的sharkey且一定要采用范围分片，可以通过<code>sh.splitAt()</code>方法预先设定区间，避免split和moveChunk的繁琐流程影响业务的正常读写。</p><blockquote><p>splitAt传入的sharkey值会将当前chunk永久分为[$minKey,传入值),[传入值,$maxKey)两个区间的chunk</p></blockquote><h4 id="BAD-CASE"><a href="#BAD-CASE" class="headerlink" title="BAD CASE"></a>BAD CASE</h4><ol><li>高频读&#x2F;写的少量数据，并且没有手动分片</li></ol><p>范围分片与哈希分片不同的地方在于，即使空表开启分片后写入数据，也只有在第一个chunk中数据大小超过64mb后才会分裂。</p><p>连单chunk大小都没到又不手动切分那分了个寂寞？</p><ol><li>递增&#x2F;递减型的shardkey且hot data is new data</li></ol><p>常见场景: IO类游戏的用户数据，拉新&#x2F;分享活动的数据</p><p>这种情况下，所有的new data永远落在末尾区间的块所在shard上，且由于mongo需要额外处理chunk的split与move，此时开启分片的性能甚至还不如业务侧做分库的性能。</p><blockquote><p> 通过Bad Case可以大致得出ranged sharkey的选择条件</p><ol><li>基数大</li><li>频率低</li><li>非单调变更</li></ol></blockquote><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h3 id="Hashed-Sharding"><a href="#Hashed-Sharding" class="headerlink" title="Hashed Sharding"></a>Hashed Sharding</h3><p>哈希分片以减少<a href="https://docs.mongodb.com/v4.2/core/sharded-cluster-query-router/#sharding-query-isolation">定向操作和增加广播操作</a>作为代价，分片集群内的数据分布更加均衡。在哈希之后，拥有比较“接近”的片键的文档将不太可能会分布在相同的数据库或者分片上。mongos更有可能执行广播操作来完成一个给定的范围查询。相对的，mongos可以将等值匹配的查询直接定位到单个分片上。</p><p>给定一个使用单调递增的值<code>X</code>作为片键的集合，使用范围分片会导致插入数据的分布类似于下面这样：</p><p><img src="/image/1712374695936.jpg" alt="1712374695936"></p><p>由于<code>X</code>的值始终在增加，因此具有<code>maxKey</code>(上限)的数据块将接收大多数传入的写操作。 这将插入操作限制在只能定向到包含此块的单个分片，从而减少或消除了分片集群中分布式写入的优势。</p><p>通过在<code>X</code>上使用哈希索引，插入的分布将类似于下面这样：</p><p><img src="/image/1712374663540(1).jpg" alt="1712374663540(1)"></p><p>由于现在数据分布更加均匀，因此可以在整个集群中更高效地读写。</p><h4 id="相较于范围分片"><a href="#相较于范围分片" class="headerlink" title="相较于范围分片"></a>相较于范围分片</h4><h5 id="优势："><a href="#优势：" class="headerlink" title="优势："></a>优势：</h5><ol><li>均摊压力</li><li>静态表&#x2F;少量数据表依然可以自动均衡的切分</li></ol><blockquote><p><strong>这里有坑：</strong></p><p>对空表开启哈希分片时，将会在每个shard新建两个chunk，后续insert数据根据shardkey哈希值落在不同的shard上</p><p>但是如果对已有数据的表开启哈希分片，当数据量小于配置chunk大小时无法自动分裂，读写压力仍然打在一个shard上</p></blockquote><h5 id="劣势："><a href="#劣势：" class="headerlink" title="劣势："></a>劣势：</h5><ol><li>对shardkey的范围查询性能差</li></ol><blockquote><p>无shardkey的查询性能差是分片集群的通病，mongos会将find广播到每一个shard，然后整理聚合结果。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Mongo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
